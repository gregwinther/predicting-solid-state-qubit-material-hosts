{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining of semiconductor materials\n",
    "\n",
    "This notebook will initially serve as an example in how to extract information of the database Materials Project [1]. \n",
    "In total, there are 126335 entries in the materials project whereas 48644 of them, roughly 39%, are deemed to be structurally similar from an experimental ICSD entry according to pymatgen's StructureMatcher algorithm. Additionally, a total of 65783 entries have been calculated to have a band gap larger than $0.1$ eV. These two have an overlap of 25271 entries, which is our starting point. \n",
    "\n",
    "The notebook will consist of 3 stages, and is strongly inspired from Ferrenti et al [2]. However, we diverge at stage 3 where we have moved the extraction of other databases out before we attend this notebook.\n",
    "\n",
    "Additionally, we will use the datamining process to find fitting and unfitting candidates. The process can be described by following some given criteria for good candidates, resulting in the label $1$. Then, we will use the complete opposite criteria to find unfitted candidates, resulting in the label $0$. \n",
    " \n",
    " \n",
    "### Contents\n",
    "  #### Fitting candidates\n",
    "    - Stage 1\n",
    "        - $50\\% + l = 0$ isotopes, with some exceptions\n",
    "        - Calculated non-magnetic \n",
    "        - Has experimental ICSD entry\n",
    "        - Crystallize in non-polar space groups\n",
    "    - Stage 2\n",
    "        - No Th, U, Cd, Hg\n",
    "        - No noble gases or rare-earth elements\n",
    "    - Stage 3\n",
    "        - bandgap restriction\n",
    "        \n",
    "  #### Unfitted candidates\n",
    "    - Stage 1\n",
    "        - $50\\% + l != 0$ isotopes\n",
    "        - Calculated magnetic\n",
    "        - Has experimental ICSD entry\n",
    "        - Crystallize in polar space groups\n",
    "    - Stage 2\n",
    "        - Include Th, U, Cd, Hg\n",
    "        - Include noble gases or rare-earth elements    \n",
    "    - Stage 3\n",
    "        - bandgap restriction\n",
    "        - Summarize bandgaps and other properties\n",
    "\n",
    "[1] Ong, S. P.; Cholia, S.; Jain, A.; Brafman, M.; Gunter, D.; Ceder, G.; \n",
    "Persson, K. a. The Materials Application Programming Interface (API): A \n",
    "simple, flexible and efficient API for materials data based on\n",
    "REpresentational State Transfer (REST) principles, Comput. Mater. Sci.,\n",
    "2015, 97, 209â€“215. doi:10.1016/j.commatsci.2014.10.037.\n",
    "\n",
    "[2] Ferrenti, A.M., de Leon, N.P., Thompson, J.D. et al. Identifying candidate hosts for quantum defects via data mining. npj Comput Mater 6, 126 (2020). https://doi.org/10.1038/s41524-020-00391-7\n",
    "\n",
    "Initially, we start of with some imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "#OPTIONAL: Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data directory /home/oliver/Dokumenter/masterprosjekt/predicting-solid-state-qubit-candidates/data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path.cwd().parent.parent / \"data\" \n",
    "print(\"Current data directory {}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for query of data\n",
    "from pymatgen import MPRester, Composition\n",
    "\n",
    "# Finding correct use of polar groups\n",
    "from src.data.utils import polarGroupUsedInMP, sortByMPID, filterIDs\n",
    "from src.visualization import visualize\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings from nan-values in  \n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "# Find and store all API-keys that are stored as environment variables .env in root folder\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "key_status = load_dotenv(find_dotenv())\n",
    "\n",
    "# Private keys. If not present, add your own secret keys here\n",
    "if (key_status):\n",
    "    MAPI_KEY = os.getenv(\"MAPI_KEY\")\n",
    "    CAPI_KEY = os.getenv(\"CAPI_KEY\")\n",
    "else: \n",
    "    MAPI_KEY = None\n",
    "    CAPI_KEY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertApproach = \"02-determined-approach\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitted candidates\n",
    "## Stage 1\n",
    "Thereafter, we need to find out what elements we want to include. The article mentioned above have some strict restrictions that are as follows: \n",
    "- $50\\% + l = 0$ isotopes\n",
    "- Calculated non-magnetic\n",
    "- Has experimental ICSD entry\n",
    "- Crystallize in non-polar space groups\n",
    "\n",
    "This stage will be done entirely through a query to pymatgen, however, the restrictions need to be set properly first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spin_zero_isotopes = [\n",
    "    \"H\", \"Li\", \"Be\", \"F\", \"Na\", \"Cl\", \"K\", \"Sc\",\n",
    "    \"V\", \"Mn\", \"Co\", \"Cu\", \"Br\", \"Rb\", \"Y\", \"Nb\", \"Tc\", \n",
    "    \"Rh\", \"Ag\", \"In\", \"Sb\", \"I\", \"Cs\", \"Lu\", \"Ta\", \"Re\", \"Ir\", \"Au\",\n",
    "    \"Tl\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"La\",\"Pr\", \"Pm\", \"Eu\", \"Tb\", \"Ho\",\n",
    "    \"Tm\", \"Ac\", \"Pa\", \"Np\", \"Pu\", \"Am\"]  #(47)\n",
    "\n",
    "#exceptions : \n",
    "# Al, P, Ga, As, B, N\n",
    "\n",
    "print(\"Number of excluded periodic-elements from isotopes: {}\".format(len(spin_zero_isotopes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_spacegroups = polarGroupUsedInMP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with MPRester(MAPI_KEY) as mpr:\n",
    "    \n",
    "    criteria = {'elements':{\"$nin\": spin_zero_isotopes}, #not included\n",
    "                    'icsd_ids': {'$gte': 0}, #All compounds deemed similar to a structure in ICSD\n",
    "                    \"magnetic_type\": {\"$eq\": \"NM\"}, #non-magnetic\n",
    "                    \"spacegroup.number\": {\"$nin\": polar_spacegroups}\n",
    "                    }\n",
    "\n",
    "    props = [\"material_id\",\"full_formula\", \"spacegroup\", \"band_gap\", \"e_above_hull\"]\n",
    "    fitted_entries = pd.DataFrame(mpr.query(criteria=criteria, properties=props))    \n",
    "        \n",
    "print(\"Number of entries after query: {}\".format(len(fitted_entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def polarGroupUnitTest(entries):\n",
    "    # Unit tests for polar groups. \n",
    "    ###############################\n",
    "    # Remove all entries with polar space groups\n",
    "    exclude_polar_space_groups =  {\n",
    "         \"triclinic\":   [\"1\"], \n",
    "         \"monoclinic\":  [\"2\", \"m\"],\n",
    "         \"orthorhombic\":[\"mm2\"],\n",
    "         \"tetragonal\":  [\"4\", \"4mm\"],\n",
    "         \"trigonal\":    [\"3\", \"3m\"],\n",
    "         \"hexagonal\":   [\"6\", \"6mm\"]\n",
    "        }\n",
    "\n",
    "    #remove polar spacegroups\n",
    "    deleteEntries = []\n",
    "    for i, entry in entries.iterrows():\n",
    "        #else: \n",
    "        if (entry[\"spacegroup\"][\"crystal_system\"]) in exclude_polar_space_groups.keys():\n",
    "            if entry[\"spacegroup\"][\"point_group\"] in exclude_polar_space_groups[entry[\"spacegroup\"][\"crystal_system\"]]:\n",
    "                deleteEntries.append(i)\n",
    "                \n",
    "    #Every delete will return a smaller dict\n",
    "    numberDeleted = 0\n",
    "    for deleteEntry in deleteEntries: \n",
    "        del entries[deleteEntry-numberDeleted]\n",
    "        numberDeleted += 1\n",
    "    if numberDeleted > 0:\n",
    "        print(\"Test not passed, polar groups could be wrong\")\n",
    "    else:\n",
    "        print(\"Polar group test passed.\")\n",
    "polarGroupUnitTest(fitted_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lowerBandGapLimit = 1.5\n",
    "\n",
    "fitted_entries = fitted_entries[fitted_entries[\"band_gap\"] >= lowerBandGapLimit]\n",
    "fitted_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_entries = fitted_entries[fitted_entries[\"e_above_hull\"]<0.2].reset_index(drop=True)\n",
    "fitted_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_entries[\"candidate\"] = np.ones(len(fitted_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfitted candidates\n",
    "## Stage 1\n",
    "\n",
    "- Calculated magnetic\n",
    "- Has experimental ICSD entry\n",
    "- Crystallize in polar space groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For total contrast in stages from good to bad candidates, add these elements.\n",
    "spin_isotopes = [\"He\",\"C\", \"O\", \"Ne\", \"Mg\", \"Si\", \"S\", \"Ar\",\n",
    "                \"Ca\", \"Ti\", \"Cr\", \"Fe\", \"Ni\", \"Zn\", \"Ge\", \"Se\",\n",
    "                \"Se\", \"Kr\", \"Sr\", \"Zr\", \"Mo\", \"Ru\", \"Pd\", \"Cd\",\n",
    "                \"Sn\", \"Te\", \"Xe\", \"Ba\", \"Hf\", \"W\", \"Os\", \"Pt\",\n",
    "                \"Hg\", \"Pb\", \"Ce\", \"Nd\", \"Sm\", \"Gd\", \"Dy\", \"Er\",\n",
    "                \"Yb\", \"Th\", \"U\"] #43\n",
    "\n",
    "#Not include the following elements:\n",
    "include_elements = [ \n",
    "    \"Th\", \"U\", \"Cd\", \"Hg\", #restriction nr 1 above (4)\n",
    "    \"He\", \"Ne\", \"Ar\", \"Kr\", \"Xe\", \"Rn\", \"Og\", #no noble gases (7)\n",
    "    \"Sc\", \"Y\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\",\n",
    "     \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\"]\n",
    "    # No rare-earth elements (17)\n",
    "\n",
    "indices = []\n",
    "for i, spin in enumerate(spin_isotopes): \n",
    "    for ele in include_elements:\n",
    "        if spin == ele:\n",
    "            indices.append(i)\n",
    "            \n",
    "for i in sorted(indices, reverse=True):\n",
    "    del spin_isotopes[i]\n",
    "\n",
    "len(spin_isotopes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with MPRester(MAPI_KEY) as mpr:\n",
    "    \n",
    "    criteria = {#'elements':{\"$nin\": spin_isotopes}, #not included\n",
    "                'icsd_ids': {'$gte': 0}, #All compounds deemed similar to a structure in ICSD\n",
    "                \"magnetic_type\": {\"$ne\": \"NM\"}, #non-magnetic not equal\n",
    "                \"spacegroup.number\": {\"$in\": polar_spacegroups}\n",
    "                }\n",
    "\n",
    "    props = [\"material_id\",\"full_formula\", \"spacegroup\", \"band_gap\"]\n",
    "    unfitted_entries = pd.DataFrame(mpr.query(criteria=criteria, properties=props))    \n",
    "        \n",
    "print(\"Number of entries after query: {}\".format(len(unfitted_entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "For consistency we are only looking at semiconductors. Thus, we will maintain a lower band gap limit for unfitted candidates, since the features we are generating are based on that a material has a band gap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBandGapLimit = 0.1\n",
    "\n",
    "unfitted_entries = unfitted_entries[unfitted_entries[\"band_gap\"] >= lowerBandGapLimit]\n",
    "unfitted_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unfitted_entries[\"candidate\"] = np.zeros(len(unfitted_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data and create training and test set\n",
    "\n",
    "In this section we will combine the data we have extracted, both from the Generated Data notebook, and the labels from the previous dataMining section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainingTargets = pd.concat([fitted_entries,unfitted_entries]).reset_index(drop=True)\n",
    "\n",
    "trainingTargets = sortByMPID(trainingTargets)\n",
    "trainingTargets = filterIDs(trainingTargets)\n",
    "trainingTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns =  [\"full_formula\", \"spacegroup\", \"band_gap\", \"e_above_hull\"]\n",
    "trainingTargets = trainingTargets.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path(data_dir / InsertApproach / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "#trainingTargets.to_pickle(data_dir / InsertApproach / \"processed\" / \"trainingCombo.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of entries in the data\n",
    "How is the distribution of entries in the different features? \n",
    "## Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedData = pd.read_pickle(data_dir / \"interim\" / \"featurized\" / \"featurized-19-03-2021.pkl\")\n",
    "trainingTargets = trainingTargets[trainingTargets[\"material_id\"].isin(generatedData[\"material_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = (\n",
    "    trainingTargets.merge(generatedData, \n",
    "              on='material_id', \n",
    "              how='outer', \n",
    "              indicator=True)\n",
    "    .query('_merge != \"both\"')\n",
    "    .drop(columns='_merge')\n",
    ")\n",
    "trainingSet = (\n",
    "    trainingTargets.merge(generatedData,\n",
    "                on=\"material_id\",\n",
    "                indicator=False,\n",
    "                how=\"left\",\n",
    "                suffixes=(False, False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testSet.shape)\n",
    "print(trainingSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.make_parallel_coordinate_matplot(trainingSet, InsertApproach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The amount of good qubit host candidates: {}, or {:0.4f}%\".format(trainingSet[trainingTargets.values==1].shape[0], trainingSet[trainingTargets.values==1].shape[0]/trainingSet.shape[0]))\n",
    "print(\"The amount of bad qubit host candidates: {}, or {:0.4f}%\".format(trainingSet[trainingTargets.values==0].shape[0], trainingSet[trainingTargets.values==0].shape[0]/trainingSet.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about elements in compounds are given in the interval:\")\n",
    "print(np.where(generatedData.columns==\"H\")[0][0],np.where(generatedData.columns==\"Pu\")[0][0])\n",
    "# plotting \n",
    "import plotly.graph_objects as go\n",
    "elements = generatedData.columns[\n",
    "    np.where(generatedData.columns==\"H\")[0][0]:np.where(generatedData.columns==\"Pu\")[0][0]\n",
    "].values\n",
    "print(len(elements))\n",
    "fig = go.Figure( \n",
    "    layout = go.Layout (\n",
    "        title=go.layout.Title(text=\"Distribution of elements in training data\"),\n",
    "        yaxis=dict(title='Number'),\n",
    "        xaxis=dict(title='Elements'),\n",
    "        xaxis_tickangle=-45\n",
    "        )\n",
    "    )\n",
    "\n",
    "width_plotly = 548.1896533333334\n",
    "\n",
    "fittedCounts = trainingSet[elements][trainingTargets.values==1].fillna(0).astype(bool).sum(axis=0)\n",
    "unFittedCounts   = trainingSet[elements][trainingTargets.values==0].fillna(0).astype(bool).sum(axis=0)\n",
    "\n",
    "fig.add_traces(go.Bar(name = \"Fitted candidates\",#prettyNames[i], \n",
    "                        x = trainingSet[elements].columns,\n",
    "                        y = fittedCounts,\n",
    "                        text = trainingSet[elements].columns,\n",
    "                        )\n",
    "                )\n",
    "fig.add_traces(go.Bar(name = \"Unfitted candidates\",#prettyNames[i], \n",
    "                        x = trainingSet[elements].columns,\n",
    "                        y = unFittedCounts,\n",
    "                        text = trainingSet[elements].columns,\n",
    "                        )\n",
    "                )\n",
    "fig.update_layout(\n",
    "                    {\"plot_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "                       \"paper_bgcolor\": \"rgba(0, 0, 0, 0)\",\n",
    "                      },\n",
    "                      font=dict(\n",
    "                        family=\"Palatino\",\n",
    "                        color=\"Black\",\n",
    "                        size=12),\n",
    "                      autosize=False,\n",
    "                      width=width_plotly*1.5,\n",
    "                      height=width_plotly/2,\n",
    "                     )\n",
    "fig.write_image(str(Path.cwd().parent.parent / \n",
    "                                    \"reports\" / \"figures\"  / \"buildingFeatures\" \n",
    "                                    / \"determined-approach-normalized-elements-histogram.pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure( \n",
    "    layout = go.Layout (\n",
    "        title=go.layout.Title(text=\"Normal adjusted counts of elements in training data\"),\n",
    "        yaxis=dict(title='Normal adjusted counts'),\n",
    "        xaxis=dict(title='Elements'),\n",
    "        xaxis_tickangle=-45\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_traces(\n",
    "    go.Bar(name = \"Fitted candidates\",#prettyNames[i], \n",
    "                   x =    trainingSet[elements].columns,\n",
    "                   y =    fittedCounts/np.sum(fittedCounts),\n",
    "                   text = trainingSet[elements].columns,\n",
    "                    )\n",
    "                )\n",
    "fig.add_traces(go.Bar(name = \"Unfitted candidates\",#prettyNames[i], \n",
    "                    x = trainingSet[elements].columns,\n",
    "                    y = unFittedCounts/np.sum(unFittedCounts),\n",
    "                    text = trainingSet[elements].columns,\n",
    "                    )\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known candidates \n",
    "\n",
    "How are the known candidates already doing in the datamining process? SiC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [\"material_id\",\"MP_Eg\",\"pretty_formula\",\"full_formula\"]\n",
    "\n",
    "#generatedData[feat][generatedData[\"pretty_formula\"]==\"SiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [\"material_id\",\"MP_Eg\",\"pretty_formula\",\"full_formula\", \"candidate\"]\n",
    "\n",
    "trainingSet[feat][(trainingSet[\"pretty_formula\"]==\"SiC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet[feat][(trainingSet[\"pretty_formula\"]==\"C\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine training targets with preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAGeneratedData = pd.read_pickle(data_dir / \"processed\" / \"processedData.pkl\")\n",
    "PCAGeneratedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = (\n",
    "    trainingTargets.merge(PCAGeneratedData,\n",
    "                on=\"material_id\",\n",
    "                indicator=False,\n",
    "                how=\"left\",\n",
    "                suffixes=(False, False))\n",
    ")\n",
    "trainingSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop new candidates that might have been added to MP after featurization \n",
    "trainingSet = trainingSet[trainingSet[\"material_id\"].isin(PCAGeneratedData[\"material_id\"])]\n",
    "trainingSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = (\n",
    "    trainingTargets.merge(PCAGeneratedData, \n",
    "              on='material_id', \n",
    "              how='outer', \n",
    "              indicator=True)\n",
    "    .query('_merge != \"both\"')\n",
    "    .drop(columns='_merge')\n",
    ")\n",
    "testSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop new candidates that might have been added to MP after featurization \n",
    "testSet = testSet[testSet[\"material_id\"].isin(PCAGeneratedData[\"material_id\"])]\n",
    "testSet.shape\n",
    "\n",
    "# Change column order\n",
    "trainingSet.insert(1, 'full_formula', trainingSet.pop(\"full_formula\"))\n",
    "testSet    .insert(1, 'full_formula', testSet    .pop(\"full_formula\"))\n",
    "testSet    .insert(1, 'pretty_formula', testSet    .pop(\"pretty_formula\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = trainingSet.drop([\"pretty_formula\"], axis=1)\n",
    "trainingTarget = trainingSet.pop(\"candidate\")\n",
    "\n",
    "Path(data_dir / InsertApproach / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "trainingSet   .to_pickle(data_dir / InsertApproach /\"processed\" / \"trainingData.pkl\")\n",
    "trainingTarget.to_pickle(data_dir / InsertApproach / \"processed\" / \"trainingTarget.pkl\")\n",
    "testSet       .to_pickle(data_dir / InsertApproach / \"processed\" / \"testSet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainingSet.copy()\n",
    "df[\"candidate\"] = trainingTarget\n",
    "df = df.groupby('candidate').apply(lambda s: s.sample(min(len(s), 300)))\n",
    "visualize.plot_2d_pca(df, df[\"candidate\"], InsertApproach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
